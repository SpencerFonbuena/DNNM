data structure: [lines, timesteps, features]
train data size: [(122030, 120, 1)]
mytest data size: [(21356, 120, 1)]
Number of classes: 4
  0%|                                                                                                                                                                                                                                                    | 0/20 [00:00<?, ?it/s]/root/DNNM/mach5 baseline/run.py:202: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  pre = torch.tensor(y_pre).cpu().detach().numpy()[0].squeeze()
/root/DNNM/mach5 baseline/run.py:203: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  act = torch.tensor(y).cpu().detach().numpy()[0].squeeze()
/root/ml/lib/python3.10/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)
  return torch._native_multi_head_attention(
/root/DNNM/mach5 baseline/run.py:235: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  pre = torch.tensor(y_pre).cpu().detach().numpy()[0].squeeze()
/root/DNNM/mach5 baseline/run.py:236: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  act = torch.tensor(y).cpu().detach().numpy()[0].squeeze()
  5%|███████████▍                                                                                                                                                                                                                         | 1/20 [1:09:05<21:52:35, 4145.02s/it]
Traceback (most recent call last):
  File "/root/DNNM/mach5 baseline/run.py", line 261, in <module>
    train()
  File "/root/DNNM/mach5 baseline/run.py", line 217, in train
    test(dataloader=test_dataloader, net=net, loss_function=loss_function)
  File "/root/DNNM/mach5 baseline/run.py", line 232, in test
    y_pre = net(x, y)
  File "/root/ml/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1538, in _call_impl
    result = forward_call(*args, **kwargs)
  File "/root/DNNM/mach5 baseline/module/transformer.py", line 58, in forward
    out = self.decoder(tgt, memory, self.tgt_mask, self.src_mask)
  File "/root/ml/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File "/root/ml/lib/python3.10/site-packages/torch/nn/modules/transformer.py", line 369, in forward
    output = mod(output, memory, tgt_mask=tgt_mask,
  File "/root/ml/lib/python3.10/site-packages/torch/nn/modules/module.py", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
KeyboardInterrupt