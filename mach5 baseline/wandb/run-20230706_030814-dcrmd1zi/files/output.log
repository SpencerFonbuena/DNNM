use device: cuda:0
use device: cuda:0
data structure: [lines, timesteps, features]
train data size: [(122030, 120, 1)]
mytest data size: [(21356, 120, 1)]
Number of classes: 4
/root/ml/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
  0%|                                                                                                           | 0/2 [00:00<?, ?it/s]/root/DNNM/mach5 baseline/run.py:198: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  pre = torch.tensor(y_pre).cpu().detach().numpy()[0].squeeze()
/root/DNNM/mach5 baseline/run.py:199: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  act = torch.tensor(y).cpu().detach().numpy()[0].squeeze()
/root/ml/lib/python3.10/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)
  return torch._native_multi_head_attention(
/root/DNNM/mach5 baseline/run.py:237: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  pre = torch.tensor(y_pre).cpu().detach().numpy()[0].squeeze()
/root/DNNM/mach5 baseline/run.py:238: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).
  act = torch.tensor(y).cpu().detach().numpy()[0].squeeze()
tensor([[ 0.9481],
        [ 0.2514],
        [-0.0867],
        [ 0.8565],
        [-5.1761],
        [-1.1304],
        [-1.5018],
        [ 0.0718],
        [-1.9686],
        [ 0.2618],
        [ 0.2244],
        [ 0.3249],
        [-0.4588],
        [ 0.5518],
        [ 0.5401],
        [ 2.8320],
        [ 0.5995],
        [-0.3561],
        [-0.1937],
        [ 0.0173],
        [ 0.6654],
        [-0.1724],
        [ 0.5779],
        [ 0.0907],
        [ 0.1288],
        [ 0.1544],
        [ 1.0951],
        [ 0.3803],
        [ 0.2023],
        [ 0.0121],
        [-0.1294],
        [-0.4374],
        [ 0.6649],
        [ 0.2455],
        [ 0.7429],
        [ 1.0274],
        [ 0.0317],
        [ 0.0731],
        [-0.7203],
        [ 0.0566],
        [-0.0281],
        [ 0.0722],
        [-0.0146],
        [ 0.3077],
        [ 0.0462],
        [-0.0908],
        [ 0.4799],
        [ 0.1317],
        [ 0.7748],
        [-0.1401],
        [-0.2386],
        [ 0.3555],
        [-0.1401],
        [ 0.2426],
        [-0.0422],
        [ 0.8243],
        [-0.1130],
        [ 0.0983],
        [ 0.3473],
        [-0.4801]], device='cuda:0')
tensor([[ 1.0115],
        [ 0.2684],
        [-0.0919],
        [ 0.9154],
        [-5.4778],
        [-1.2182],
        [-1.6133],
        [ 0.0762],
        [-2.0933],
        [ 0.2809],
        [ 0.2399],
        [ 0.3486],
        [-0.4946],
        [ 0.5935],
        [ 0.5794],
        [ 3.0220],
        [ 0.6421],
        [-0.3822],
        [-0.2073],
        [ 0.0218],
        [ 0.7229],
        [-0.1802],
        [ 0.6277],
        [ 0.1024],
        [ 0.1427],
        [ 0.1695],
        [ 1.1770],
        [ 0.4102],
        [ 0.2177],
        [ 0.0129],
        [-0.1390],
        [-0.4692],
        [ 0.7139],
        [ 0.2623],
        [ 0.7969],
        [ 1.1025],
        [ 0.0348],
        [ 0.0813],
        [-0.7704],
        [ 0.0615],
        [-0.0318],
        [ 0.0748],
        [-0.0185],
        [ 0.3280],
        [ 0.0481],
        [-0.0984],
        [ 0.5143],
        [ 0.1412],
        [ 0.8327],
        [-0.1512],
        [-0.2575],
        [ 0.3802],
        [-0.1512],
        [ 0.2604],
        [-0.0450],
        [ 0.8842],
        [-0.1244],
        [ 0.1008],
        [ 0.3697],
        [-0.5122]], device='cuda:0')
  0%|                                                                                                           | 0/2 [09:14<?, ?it/s]
Traceback (most recent call last):
  File "/root/DNNM/mach5 baseline/run.py", line 272, in <module>
    train()
  File "/root/DNNM/mach5 baseline/run.py", line 215, in train
    test(dataloader=test_dataloader, net=net, loss_function=loss_function)
  File "/root/DNNM/mach5 baseline/run.py", line 230, in test
    for i, (x, y) in enumerate(dataloader):
  File "/root/ml/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 633, in __next__
    data = self._next_data()
  File "/root/ml/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1345, in _next_data
    return self._process_data(data)
  File "/root/ml/lib/python3.10/site-packages/torch/utils/data/dataloader.py", line 1371, in _process_data
    data.reraise()
  File "/root/ml/lib/python3.10/site-packages/torch/_utils.py", line 644, in reraise
    raise exception
IndexError: Caught IndexError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File "/root/ml/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py", line 308, in _worker_loop
    data = fetcher.fetch(index)
  File "/root/ml/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/root/ml/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py", line 51, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "/root/DNNM/mach5 baseline/dataset_process/dataset_process.py", line 138, in __getitem__
    return self.valdata[index], self.vallabels[index]
IndexError: index 21356 is out of bounds for dimension 0 with size 21356