use device: cuda:0
use device: cuda:0
data structure: [lines, timesteps, features]
train data size: [(122030, 120, 1)]
mytest data size: [(21356, 120, 1)]
Number of classes: 4
/root/ml/lib/python3.10/site-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML
  warnings.warn("Can't initialize NVML")
/root/ml/lib/python3.10/site-packages/torch/nn/modules/activation.py:1160: UserWarning: Converting mask without torch.bool dtype to bool; this will negatively affect performance. Prefer to use a boolean mask directly. (Triggered internally at ../aten/src/ATen/native/transformers/attention.cpp:150.)
  return torch._native_multi_head_attention(
Traceback (most recent call last):
  File "/root/DNNM/mach5 baseline/infer.py", line 157, in <module>
    infer()
  File "/root/DNNM/mach5 baseline/infer.py", line 141, in infer
    predictions = hp.scaler.inverse_transform(predictions)
  File "/root/ml/lib/python3.10/site-packages/sklearn/preprocessing/_data.py", line 1034, in inverse_transform
    X = check_array(
  File "/root/ml/lib/python3.10/site-packages/sklearn/utils/validation.py", line 879, in check_array
    array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)
  File "/root/ml/lib/python3.10/site-packages/sklearn/utils/_array_api.py", line 185, in _asarray_with_order
    array = numpy.asarray(array, order=order, dtype=dtype)
  File "/root/ml/lib/python3.10/site-packages/torch/_tensor.py", line 972, in __array__
    return self.numpy().astype(dtype, copy=False)
TypeError: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.